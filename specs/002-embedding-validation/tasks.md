# Implementation Tasks: Hugging Face ì„ë² ë”© í†µí•©

**Feature**: 002-embedding-validation
**Version**: 1.0.0
**Last Updated**: 2025-01-17

---

## ì‘ì—… ê°œìš”

**ì´ ì‘ì—… ìˆ˜**: 9ê°œ (T041-T049)
**ì˜ˆìƒ ì‹œê°„**: 32ì‹œê°„ (3ì£¼)
**í˜„ì¬ ìƒíƒœ**: Planning â†’ Ready for Implementation

---

## Phase 4: Hugging Face ì„ë² ë”© ê²€ì¦ ë° í†µí•©

### T041: ëª¨ë¸ ì„¤ì • ê²€ì¦

**ìš°ì„ ìˆœìœ„**: P1 (Critical)
**ì˜ˆìƒ ì‹œê°„**: 1ì‹œê°„
**ë‹´ë‹¹**: Backend Developer
**ì„ í–‰ ì‘ì—…**: Phase 1-2 ì™„ë£Œ (T001-T017)

#### ëª©í‘œ
ê¸°ì¡´ì— ì„¤ì •ëœ Hugging Face ì„ë² ë”© ëª¨ë¸ì´ ì •ìƒì ìœ¼ë¡œ ë¡œë”©ë˜ê³  ì‘ë™í•˜ëŠ”ì§€ ê²€ì¦

#### ì‘ì—… ë‚´ìš©
1. **ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í™•ì¸**
   ```bash
   python scripts/download_embedding_model.py
   ```
   - ëª¨ë¸ì´ ìºì‹œ ë””ë ‰í† ë¦¬ì— ë‹¤ìš´ë¡œë“œë˜ëŠ”ì§€ í™•ì¸
   - ë‹¤ìš´ë¡œë“œ ê²½ë¡œ: `~/.cache/torch/sentence_transformers/`
   - ëª¨ë¸ í¬ê¸°: ~470MB

2. **ì„ë² ë”© ì°¨ì› ê²€ì¦**
   ```python
   from sentence_transformers import SentenceTransformer
   model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
   assert model.get_sentence_embedding_dimension() == 384
   ```

3. **í•œêµ­ì–´ í…ìŠ¤íŠ¸ í…ŒìŠ¤íŠ¸**
   ```python
   embedding = model.encode("ì•ˆë…•í•˜ì„¸ìš”")
   assert len(embedding) == 384
   assert embedding.dtype == np.float32
   ```

4. **ì„¤ì • íŒŒì¼ ê²€ì¦**
   - `config/settings.py`ì— `EMBEDDING_CONFIG` í™•ì¸
   - `src/models/embedding.py`ì— `EmbeddingConfiguration` í´ë˜ìŠ¤ í™•ì¸
   - `.env` íŒŒì¼ì— í™˜ê²½ ë³€ìˆ˜ ì„¤ì • í™•ì¸

#### ìˆ˜ë½ ê¸°ì¤€
- âœ… ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œë¨
- âœ… ì„ë² ë”© ì°¨ì›ì´ 384ì„ì„ í™•ì¸
- âœ… í•œêµ­ì–´ í…ìŠ¤íŠ¸ê°€ ì •ìƒì ìœ¼ë¡œ ì„ë² ë”©ë¨
- âœ… ì„¤ì • íŒŒì¼ì´ ëª¨ë‘ ì˜¬ë°”ë¥´ê²Œ êµ¬ì„±ë¨

#### ì‚°ì¶œë¬¼
- ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸: `scripts/validate_embedding_model.py`
- ê²€ì¦ ë¦¬í¬íŠ¸: `docs/model-validation-report.md`

---

### T042: ì„ë² ë”© ì„œë¹„ìŠ¤ êµ¬í˜„ â­

**ìš°ì„ ìˆœìœ„**: P0 (Critical)
**ì˜ˆìƒ ì‹œê°„**: 4ì‹œê°„
**ë‹´ë‹¹**: Backend Developer
**ì„ í–‰ ì‘ì—…**: T041

#### ëª©í‘œ
`HuggingFaceEmbedding` í´ë˜ìŠ¤ë¥¼ êµ¬í˜„í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ 384ì°¨ì› ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜

#### ì‘ì—… ë‚´ìš©

##### 1. íŒŒì¼ ìƒì„±
**íŒŒì¼**: `src/services/embeddings.py`

##### 2. í´ë˜ìŠ¤ êµ¬ì¡° ì‘ì„±
```python
from typing import List, Optional
from sentence_transformers import SentenceTransformer
from src.models.embedding import EmbeddingConfiguration
import logging

logger = logging.getLogger(__name__)

class HuggingFaceEmbedding:
    """
    Hugging Face sentence-transformers ê¸°ë°˜ ì„ë² ë”© ì„œë¹„ìŠ¤

    Responsibilities:
    - í…ìŠ¤íŠ¸ë¥¼ 384ì°¨ì› ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜
    - ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì²˜ë¦¬ëŸ‰ ìµœì í™”
    - L2 ì •ê·œí™”ëœ ë²¡í„° ìƒì„± (cosine similarityìš©)
    """

    def __init__(self, config: EmbeddingConfiguration):
        # ì´ˆê¸°í™” ë¡œì§
        pass

    def embed_text(self, text: str) -> List[float]:
        # ë‹¨ì¼ í…ìŠ¤íŠ¸ ì„ë² ë”©
        pass

    def embed_texts(
        self,
        texts: List[str],
        batch_size: Optional[int] = None
    ) -> List[List[float]]:
        # ë°°ì¹˜ í…ìŠ¤íŠ¸ ì„ë² ë”©
        pass

    def get_embedding_dimension(self) -> int:
        # ì„ë² ë”© ì°¨ì› ë°˜í™˜
        pass

    def validate_model(self) -> bool:
        # ëª¨ë¸ ê²€ì¦
        pass
```

##### 3. ë©”ì„œë“œ êµ¬í˜„

**`__init__` ë©”ì„œë“œ**:
```python
def __init__(self, config: EmbeddingConfiguration):
    """ì„ë² ë”© ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
    self.config = config
    self.model = SentenceTransformer(
        config.model_name,
        device=config.device.value
    )
    self.embedding_dim = config.embedding_dim
    logger.info(
        f"Initialized HuggingFaceEmbedding with model={config.model_name}, "
        f"device={config.device.value}, dim={self.embedding_dim}"
    )
```

**`embed_text` ë©”ì„œë“œ**:
```python
def embed_text(self, text: str) -> List[float]:
    """ë‹¨ì¼ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜"""
    if not text.strip():
        raise ValueError("Empty text cannot be embedded")

    embedding = self.model.encode(
        text,
        convert_to_numpy=True,
        normalize_embeddings=True  # L2 ì •ê·œí™”
    )

    logger.debug(f"Embedded text (length={len(text)}) to {len(embedding)}-dim vector")
    return embedding.tolist()
```

**`embed_texts` ë©”ì„œë“œ**:
```python
def embed_texts(
    self,
    texts: List[str],
    batch_size: Optional[int] = None
) -> List[List[float]]:
    """ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ ë°°ì¹˜ë¡œ ì„ë² ë”©"""
    if not texts:
        raise ValueError("Empty text list cannot be embedded")

    batch_size = batch_size or self.config.batch_size

    logger.info(f"Embedding {len(texts)} texts with batch_size={batch_size}")

    embeddings = self.model.encode(
        texts,
        batch_size=batch_size,
        convert_to_numpy=True,
        normalize_embeddings=True,
        show_progress_bar=True  # tqdm progress bar
    )

    return embeddings.tolist()
```

**`get_embedding_dimension` ë©”ì„œë“œ**:
```python
def get_embedding_dimension(self) -> int:
    """ì„ë² ë”© ì°¨ì› ë°˜í™˜ (384)"""
    return self.embedding_dim
```

**`validate_model` ë©”ì„œë“œ**:
```python
def validate_model(self) -> bool:
    """ëª¨ë¸ ë¡œë”© ë° ê¸°ë³¸ ê¸°ëŠ¥ ê²€ì¦"""
    try:
        test_text = "í…ŒìŠ¤íŠ¸"
        test_embedding = self.embed_text(test_text)

        # ì°¨ì› í™•ì¸
        is_valid = len(test_embedding) == self.embedding_dim

        # L2 ì •ê·œí™” í™•ì¸
        import numpy as np
        magnitude = np.linalg.norm(test_embedding)
        is_normalized = abs(magnitude - 1.0) < 1e-6

        logger.info(f"Model validation: valid={is_valid}, normalized={is_normalized}")
        return is_valid and is_normalized
    except Exception as e:
        logger.error(f"Model validation failed: {e}")
        return False
```

##### 4. ì—ëŸ¬ ì²˜ë¦¬
- ë¹ˆ í…ìŠ¤íŠ¸ ì…ë ¥ â†’ `ValueError`
- ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì…ë ¥ â†’ `ValueError`
- ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨ â†’ `RuntimeError`
- ê¸´ í…ìŠ¤íŠ¸ (>512 í† í°) â†’ ìë™ truncation (sentence-transformers ê¸°ë³¸ ë™ì‘)

##### 5. ë¡œê¹… ì¶”ê°€
- INFO: ì´ˆê¸°í™”, ë°°ì¹˜ ì„ë² ë”© ì‹œì‘/ì™„ë£Œ
- DEBUG: ë‹¨ì¼ ì„ë² ë”© ìƒì„±
- ERROR: ì—ëŸ¬ ë°œìƒ ì‹œ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤

#### ìˆ˜ë½ ê¸°ì¤€
- âœ… `HuggingFaceEmbedding` í´ë˜ìŠ¤ êµ¬í˜„ ì™„ë£Œ
- âœ… ë‹¨ì¼ í…ìŠ¤íŠ¸ ì„ë² ë”© ì„±ê³µ (í•œêµ­ì–´ í¬í•¨)
- âœ… ë°°ì¹˜ 100ê°œ í…ìŠ¤íŠ¸ ì„ë² ë”© ì„±ê³µ
- âœ… ë¹ˆ í…ìŠ¤íŠ¸ ì…ë ¥ ì‹œ `ValueError` ë°œìƒ
- âœ… L2 ì •ê·œí™”ëœ ë²¡í„° ìƒì„± í™•ì¸ (magnitude â‰ˆ 1.0)
- âœ… ì„ë² ë”© ì°¨ì› 384 í™•ì¸
- âœ… `validate_model()` í…ŒìŠ¤íŠ¸ í†µê³¼

#### ì‚°ì¶œë¬¼
- `src/services/embeddings.py` (ìƒˆ íŒŒì¼)

---

### T043: ChromaDB í†µí•©

**ìš°ì„ ìˆœìœ„**: P0 (Critical)
**ì˜ˆìƒ ì‹œê°„**: 3ì‹œê°„
**ë‹´ë‹¹**: Backend Developer
**ì„ í–‰ ì‘ì—…**: T042

#### ëª©í‘œ
`VectorStore` í´ë˜ìŠ¤ë¥¼ ì—…ë°ì´íŠ¸í•˜ì—¬ `HuggingFaceEmbedding` ì„œë¹„ìŠ¤ì™€ í†µí•©

#### ì‘ì—… ë‚´ìš©

##### 1. VectorStore í´ë˜ìŠ¤ ìˆ˜ì •

**íŒŒì¼**: `src/services/vector_store.py`

##### 2. `__init__` ë©”ì„œë“œ ì—…ë°ì´íŠ¸
```python
class VectorStore:
    def __init__(
        self,
        config: ChromaDBConfig,
        embedding_service: HuggingFaceEmbedding  # ğŸ†• ì¶”ê°€
    ):
        """ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”"""
        self.config = config
        self.embedding_service = embedding_service  # ğŸ†•

        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        import chromadb
        self.client = chromadb.PersistentClient(
            path=config.persist_directory
        )

        # ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±
        self.collection = self.client.get_or_create_collection(
            name=config.collection_name,
            metadata={"hnsw:space": config.distance_function}
        )

        logger.info(
            f"Initialized VectorStore with collection={config.collection_name}, "
            f"embedding_dim={embedding_service.get_embedding_dimension()}"
        )
```

##### 3. `add_documents` ë©”ì„œë“œ ì—…ë°ì´íŠ¸
```python
def add_documents(
    self,
    documents: List[str],
    metadatas: Optional[List[Dict]] = None,
    embeddings: Optional[List[List[float]]] = None,
    ids: Optional[List[str]] = None
) -> Dict[str, Any]:
    """
    ë¬¸ì„œë¥¼ ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€

    Args:
        documents: ë¬¸ì„œ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        metadatas: ê° ë¬¸ì„œì˜ ë©”íƒ€ë°ì´í„°
        embeddings: Pre-computed embeddings (Noneì´ë©´ ìë™ ìƒì„±)
        ids: ë¬¸ì„œ ID ë¦¬ìŠ¤íŠ¸

    Returns:
        {"success": bool, "count": int, "ids": List[str]}
    """
    # ğŸ†• ì„ë² ë”©ì´ ì—†ìœ¼ë©´ embedding_serviceë¡œ ìƒì„±
    if embeddings is None:
        logger.info(f"Generating embeddings for {len(documents)} documents")
        embeddings = self.embedding_service.embed_texts(documents)

    # ID ìƒì„± (ì—†ìœ¼ë©´)
    if ids is None:
        import uuid
        ids = [str(uuid.uuid4()) for _ in documents]

    # ChromaDBì— ì €ì¥
    self.collection.add(
        embeddings=embeddings,
        documents=documents,
        metadatas=metadatas,
        ids=ids
    )

    logger.info(f"Added {len(documents)} documents to collection")

    return {
        "success": True,
        "count": len(documents),
        "ids": ids
    }
```

##### 4. `query` ë©”ì„œë“œ ì—…ë°ì´íŠ¸
```python
def query(
    self,
    query_text: str,
    top_k: int = 5,
    filter: Optional[Dict] = None
) -> Dict[str, Any]:
    """
    ì¿¼ë¦¬ í…ìŠ¤íŠ¸ë¡œ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰

    Args:
        query_text: ê²€ìƒ‰ ì¿¼ë¦¬
        top_k: ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜
        filter: ë©”íƒ€ë°ì´í„° í•„í„°

    Returns:
        {
            "documents": List[str],
            "metadatas": List[Dict],
            "distances": List[float],
            "ids": List[str]
        }
    """
    # ğŸ†• ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
    logger.debug(f"Generating embedding for query: {query_text[:50]}...")
    query_embedding = self.embedding_service.embed_text(query_text)

    # ChromaDB ê²€ìƒ‰
    results = self.collection.query(
        query_embeddings=[query_embedding],
        n_results=top_k,
        where=filter
    )

    logger.info(f"Query returned {len(results['documents'][0])} results")

    return {
        "documents": results["documents"][0],
        "metadatas": results["metadatas"][0],
        "distances": results["distances"][0],
        "ids": results["ids"][0]
    }
```

##### 5. ê¸°ì¡´ ChromaDB ê¸°ë³¸ ì„ë² ë” ì œê±°
- ChromaDB collection ìƒì„± ì‹œ `embedding_function` íŒŒë¼ë¯¸í„° ì œê±°
- Pre-computed embeddingsë§Œ ì‚¬ìš©
- ë¡œê·¸ì—ì„œ ChromaDB ê¸°ë³¸ ì„ë² ë” í˜¸ì¶œ í™•ì¸ (0ê±´ì´ì–´ì•¼ í•¨)

##### 6. í…ŒìŠ¤íŠ¸ ì½”ë“œ ì—…ë°ì´íŠ¸
**íŒŒì¼**: `tests/integration/test_vector_store.py`
```python
def test_vector_store_with_embedding_service():
    """VectorStoreê°€ HuggingFaceEmbeddingì„ ì‚¬ìš©í•˜ëŠ”ì§€ í™•ì¸"""
    # Setup
    embedding_config = EmbeddingConfiguration()
    embedding_service = HuggingFaceEmbedding(embedding_config)

    chroma_config = ChromaDBConfig()
    vector_store = VectorStore(chroma_config, embedding_service)

    # Test
    documents = ["í…ŒìŠ¤íŠ¸ ë¬¸ì„œ 1", "í…ŒìŠ¤íŠ¸ ë¬¸ì„œ 2"]
    result = vector_store.add_documents(documents)

    assert result["success"] is True
    assert result["count"] == 2

    # Query
    query_result = vector_store.query("í…ŒìŠ¤íŠ¸", top_k=2)
    assert len(query_result["documents"]) == 2
```

#### ìˆ˜ë½ ê¸°ì¤€
- âœ… `VectorStore.__init__`ì— `embedding_service` íŒŒë¼ë¯¸í„° ì¶”ê°€
- âœ… `add_documents`ì—ì„œ ì„ë² ë”© ìë™ ìƒì„±
- âœ… `query`ì—ì„œ ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
- âœ… ChromaDB ê¸°ë³¸ ì„ë² ë” í˜¸ì¶œ 0ê±´ (ë¡œê·¸ í™•ì¸)
- âœ… 1000ê°œ ë¬¸ì„œ ì¶”ê°€ í…ŒìŠ¤íŠ¸ í†µê³¼
- âœ… ì¿¼ë¦¬ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ í†µê³¼

#### ì‚°ì¶œë¬¼
- `src/services/vector_store.py` (ì—…ë°ì´íŠ¸)
- `tests/integration/test_vector_store.py` (ì—…ë°ì´íŠ¸)

---

### T044: ë¬¸ì„œ ì¸ë±ì‹± ìœ í‹¸ë¦¬í‹°

**ìš°ì„ ìˆœìœ„**: P1 (High)
**ì˜ˆìƒ ì‹œê°„**: 4ì‹œê°„
**ë‹´ë‹¹**: Backend Developer
**ì„ í–‰ ì‘ì—…**: T043

#### ëª©í‘œ
ëŒ€ëŸ‰ ë¬¸ì„œë¥¼ ì¸ë±ì‹±í•˜ëŠ” CLI ìœ í‹¸ë¦¬í‹° ì‘ì„±

#### ì‘ì—… ë‚´ìš©

##### 1. íŒŒì¼ ìƒì„±
**íŒŒì¼**: `scripts/index_documents.py`

##### 2. CLI ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„
```python
import argparse
import json
import logging
from pathlib import Path
from typing import List, Dict
from tqdm import tqdm

from src.services.embeddings import HuggingFaceEmbedding
from src.services.vector_store import VectorStore
from src.models.embedding import EmbeddingConfiguration
from src.config.chroma import ChromaDBConfig

logger = logging.getLogger(__name__)

def parse_args():
    parser = argparse.ArgumentParser(
        description="Bulk document indexing for vector store"
    )
    parser.add_argument(
        "--source",
        type=str,
        required=True,
        help="Source directory or file path"
    )
    parser.add_argument(
        "--format",
        type=str,
        choices=["json", "md", "pdf", "csv"],
        default="json",
        help="Document format"
    )
    parser.add_argument(
        "--batch-size",
        type=int,
        default=100,
        help="Batch size for embedding generation"
    )
    parser.add_argument(
        "--text-column",
        type=str,
        default="text",
        help="Column name for text content (CSV/JSON)"
    )
    return parser.parse_args()
```

##### 3. ë¬¸ì„œ ë¡œë” êµ¬í˜„
```python
def load_json_documents(file_path: Path, text_column: str) -> List[Dict]:
    """JSON íŒŒì¼ì—ì„œ ë¬¸ì„œ ë¡œë“œ"""
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    if isinstance(data, list):
        return data
    else:
        return [data]

def load_markdown_documents(file_path: Path) -> List[Dict]:
    """Markdown íŒŒì¼ì—ì„œ ë¬¸ì„œ ë¡œë“œ"""
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()

    return [{
        "text": content,
        "source": str(file_path),
        "format": "markdown"
    }]

def load_csv_documents(file_path: Path, text_column: str) -> List[Dict]:
    """CSV íŒŒì¼ì—ì„œ ë¬¸ì„œ ë¡œë“œ"""
    import csv
    documents = []

    with open(file_path, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            if text_column in row:
                documents.append(row)

    return documents
```

##### 4. ë°°ì¹˜ ì²˜ë¦¬ ë¡œì§
```python
def index_documents(
    documents: List[Dict],
    vector_store: VectorStore,
    batch_size: int,
    text_column: str
) -> Dict[str, int]:
    """ë¬¸ì„œë¥¼ ë°°ì¹˜ë¡œ ì¸ë±ì‹±"""
    total = len(documents)
    success_count = 0
    error_count = 0

    # ì§„í–‰ ìƒí™© í‘œì‹œ
    with tqdm(total=total, desc="Indexing documents") as pbar:
        for i in range(0, total, batch_size):
            batch = documents[i:i + batch_size]

            try:
                # í…ìŠ¤íŠ¸ ë° ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
                texts = [doc[text_column] for doc in batch]
                metadatas = [
                    {k: v for k, v in doc.items() if k != text_column}
                    for doc in batch
                ]

                # ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€
                result = vector_store.add_documents(
                    documents=texts,
                    metadatas=metadatas
                )

                success_count += result["count"]

            except Exception as e:
                logger.error(f"Failed to index batch {i//batch_size}: {e}")
                error_count += len(batch)

            pbar.update(len(batch))

    return {
        "total": total,
        "success": success_count,
        "errors": error_count
    }
```

##### 5. Main í•¨ìˆ˜
```python
def main():
    args = parse_args()

    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    embedding_config = EmbeddingConfiguration(batch_size=args.batch_size)
    embedding_service = HuggingFaceEmbedding(embedding_config)

    chroma_config = ChromaDBConfig()
    vector_store = VectorStore(chroma_config, embedding_service)

    # ë¬¸ì„œ ë¡œë“œ
    source_path = Path(args.source)

    if source_path.is_file():
        # ë‹¨ì¼ íŒŒì¼
        if args.format == "json":
            documents = load_json_documents(source_path, args.text_column)
        elif args.format == "md":
            documents = load_markdown_documents(source_path)
        elif args.format == "csv":
            documents = load_csv_documents(source_path, args.text_column)
    else:
        # ë””ë ‰í† ë¦¬
        documents = []
        for file_path in source_path.glob(f"*.{args.format}"):
            if args.format == "json":
                documents.extend(load_json_documents(file_path, args.text_column))
            elif args.format == "md":
                documents.extend(load_markdown_documents(file_path))

    logger.info(f"Loaded {len(documents)} documents from {args.source}")

    # ì¸ë±ì‹±
    stats = index_documents(
        documents=documents,
        vector_store=vector_store,
        batch_size=args.batch_size,
        text_column=args.text_column
    )

    # ê²°ê³¼ ì¶œë ¥
    print("\n=== Indexing Results ===")
    print(f"Total documents: {stats['total']}")
    print(f"Successfully indexed: {stats['success']}")
    print(f"Errors: {stats['errors']}")
    print(f"Success rate: {stats['success']/stats['total']*100:.1f}%")

if __name__ == "__main__":
    main()
```

#### ìˆ˜ë½ ê¸°ì¤€
- âœ… JSON, Markdown, CSV íŒŒì¼ ë¡œë”© ì§€ì›
- âœ… ë°°ì¹˜ í¬ê¸° 100ìœ¼ë¡œ ì²˜ë¦¬ ê°€ëŠ¥
- âœ… tqdm progress bar ì •ìƒ í‘œì‹œ
- âœ… 1000ê°œ ë¬¸ì„œ ì¸ë±ì‹± ì™„ë£Œ ì‹œê°„ â‰¤5ë¶„
- âœ… ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„ ë¡œì§ ì‘ë™
- âœ… ì¸ë±ì‹± í†µê³„ ì¶œë ¥ (ì„±ê³µ/ì‹¤íŒ¨ ì¹´ìš´íŠ¸)

#### ì‚°ì¶œë¬¼
- `scripts/index_documents.py` (ìƒˆ íŒŒì¼)

---

### T045: í•œêµ­ì–´ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

**ìš°ì„ ìˆœìœ„**: P0 (Critical)
**ì˜ˆìƒ ì‹œê°„**: 3ì‹œê°„
**ë‹´ë‹¹**: QA Engineer
**ì„ í–‰ ì‘ì—…**: T042

#### ëª©í‘œ
`HuggingFaceEmbedding` ì„œë¹„ìŠ¤ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„± (100% ì»¤ë²„ë¦¬ì§€)

#### ì‘ì—… ë‚´ìš©

##### 1. í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
**íŒŒì¼**: `tests/unit/test_embeddings.py`

##### 2. í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‘ì„±

```python
import pytest
import numpy as np
from src.services.embeddings import HuggingFaceEmbedding
from src.models.embedding import EmbeddingConfiguration, DeviceType

class TestHuggingFaceEmbedding:
    """HuggingFaceEmbedding ì„œë¹„ìŠ¤ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸"""

    @pytest.fixture
    def embedding_service(self):
        """ì„ë² ë”© ì„œë¹„ìŠ¤ fixture"""
        config = EmbeddingConfiguration()
        return HuggingFaceEmbedding(config)

    def test_initialization(self, embedding_service):
        """ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
        assert embedding_service.embedding_dim == 384
        assert embedding_service.config.model_name == "paraphrase-multilingual-MiniLM-L12-v2"

    def test_embed_single_korean_text(self, embedding_service):
        """í•œêµ­ì–´ ë‹¨ì¼ í…ìŠ¤íŠ¸ ì„ë² ë”©"""
        text = "ì•ˆë…•í•˜ì„¸ìš”"
        embedding = embedding_service.embed_text(text)

        assert len(embedding) == 384
        assert isinstance(embedding, list)
        assert all(isinstance(x, float) for x in embedding)

    def test_embed_single_english_text(self, embedding_service):
        """ì˜ì–´ ë‹¨ì¼ í…ìŠ¤íŠ¸ ì„ë² ë”©"""
        text = "Hello world"
        embedding = embedding_service.embed_text(text)

        assert len(embedding) == 384

    def test_embed_mixed_text(self, embedding_service):
        """í•œì˜ í˜¼í•© í…ìŠ¤íŠ¸ ì„ë² ë”©"""
        text = "PostgreSQL ë°ì´í„°ë² ì´ìŠ¤"
        embedding = embedding_service.embed_text(text)

        assert len(embedding) == 384

    def test_embed_empty_text_raises_error(self, embedding_service):
        """ë¹ˆ í…ìŠ¤íŠ¸ ì…ë ¥ ì‹œ ValueError ë°œìƒ"""
        with pytest.raises(ValueError, match="Empty text"):
            embedding_service.embed_text("")

        with pytest.raises(ValueError, match="Empty text"):
            embedding_service.embed_text("   ")  # ê³µë°±ë§Œ

    def test_embed_batch_texts(self, embedding_service):
        """ë°°ì¹˜ í…ìŠ¤íŠ¸ ì„ë² ë”©"""
        texts = [
            "ë°ì´í„°ë² ì´ìŠ¤ íŠ¸ëœì­ì…˜",
            "SQL ì¿¼ë¦¬ ìµœì í™”",
            "NoSQLê³¼ ê´€ê³„í˜• ë°ì´í„°ë² ì´ìŠ¤"
        ]
        embeddings = embedding_service.embed_texts(texts)

        assert len(embeddings) == 3
        assert all(len(emb) == 384 for emb in embeddings)

    def test_embed_large_batch(self, embedding_service):
        """ëŒ€ëŸ‰ ë°°ì¹˜ ì„ë² ë”© (100ê°œ)"""
        texts = [f"í…ŒìŠ¤íŠ¸ ë¬¸ì„œ {i}" for i in range(100)]
        embeddings = embedding_service.embed_texts(texts, batch_size=50)

        assert len(embeddings) == 100
        assert all(len(emb) == 384 for emb in embeddings)

    def test_embed_empty_list_raises_error(self, embedding_service):
        """ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì…ë ¥ ì‹œ ValueError ë°œìƒ"""
        with pytest.raises(ValueError, match="Empty text list"):
            embedding_service.embed_texts([])

    def test_embedding_normalization(self, embedding_service):
        """L2 ì •ê·œí™” í™•ì¸"""
        text = "í…ŒìŠ¤íŠ¸"
        embedding = embedding_service.embed_text(text)

        magnitude = np.linalg.norm(embedding)
        assert abs(magnitude - 1.0) < 1e-6  # L2 ì •ê·œí™” í™•ì¸

    def test_get_embedding_dimension(self, embedding_service):
        """ì„ë² ë”© ì°¨ì› ë°˜í™˜"""
        assert embedding_service.get_embedding_dimension() == 384

    def test_validate_model(self, embedding_service):
        """ëª¨ë¸ ê²€ì¦"""
        is_valid = embedding_service.validate_model()
        assert is_valid is True

    def test_long_text_truncation(self, embedding_service):
        """ê¸´ í…ìŠ¤íŠ¸ (>512 í† í°) ìë™ truncation"""
        # ë§¤ìš° ê¸´ í…ìŠ¤íŠ¸ ìƒì„±
        long_text = "í…ŒìŠ¤íŠ¸ " * 300  # ~600 í† í°

        embedding = embedding_service.embed_text(long_text)

        # truncationë˜ì–´ë„ ì„ë² ë”© ìƒì„± ì„±ê³µ
        assert len(embedding) == 384

    def test_special_characters(self, embedding_service):
        """íŠ¹ìˆ˜ ë¬¸ì ì²˜ë¦¬"""
        text = "SQLì˜ WHERE ì¡°ê±´ì ˆ (condition)"
        embedding = embedding_service.embed_text(text)

        assert len(embedding) == 384

    def test_unicode_text(self, embedding_service):
        """ìœ ë‹ˆì½”ë“œ í…ìŠ¤íŠ¸ ì²˜ë¦¬"""
        text = "í•œê¸€, æ—¥æœ¬èª, ä¸­æ–‡"
        embedding = embedding_service.embed_text(text)

        assert len(embedding) == 384

    def test_consistent_embeddings(self, embedding_service):
        """ë™ì¼ í…ìŠ¤íŠ¸ëŠ” ë™ì¼ ì„ë² ë”© ìƒì„±"""
        text = "ì¼ê´€ì„± í…ŒìŠ¤íŠ¸"

        embedding1 = embedding_service.embed_text(text)
        embedding2 = embedding_service.embed_text(text)

        # ì„ë² ë”©ì´ ë™ì¼í•œì§€ í™•ì¸
        np.testing.assert_array_almost_equal(embedding1, embedding2, decimal=6)
```

#### ìˆ˜ë½ ê¸°ì¤€
- âœ… 15ê°œ ì´ìƒ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‘ì„±
- âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼
- âœ… `src/services/embeddings.py` ì»¤ë²„ë¦¬ì§€ 100%
- âœ… í•œêµ­ì–´, ì˜ì–´, í˜¼í•© í…ìŠ¤íŠ¸ í…ŒìŠ¤íŠ¸ í¬í•¨
- âœ… ì—ëŸ¬ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸ í¬í•¨

#### ì‚°ì¶œë¬¼
- `tests/unit/test_embeddings.py` (ìƒˆ íŒŒì¼)

---

### T046: ë²¡í„° ê²€ìƒ‰ ì§€ì—°ì‹œê°„ í…ŒìŠ¤íŠ¸

**ìš°ì„ ìˆœìœ„**: P1 (High)
**ì˜ˆìƒ ì‹œê°„**: 4ì‹œê°„
**ë‹´ë‹¹**: QA Engineer
**ì„ í–‰ ì‘ì—…**: T043

#### ëª©í‘œ
ê²€ìƒ‰ ì‘ë‹µì‹œê°„ SLA ê²€ì¦ (P95 â‰¤0.5ì´ˆ)

#### ì‘ì—… ë‚´ìš©

##### 1. í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
**íŒŒì¼**: `tests/integration/test_vector_search.py`

##### 2. í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‘ì„±

```python
import pytest
import time
import numpy as np
from src.services.embeddings import HuggingFaceEmbedding
from src.services.vector_store import VectorStore
from src.models.embedding import EmbeddingConfiguration
from src.config.chroma import ChromaDBConfig

class TestVectorSearchPerformance:
    """ë²¡í„° ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""

    @pytest.fixture(scope="class")
    def setup_vector_store(self):
        """1000ê°œ ë¬¸ì„œê°€ ì¸ë±ì‹±ëœ ë²¡í„° ìŠ¤í† ì–´ ìƒì„±"""
        embedding_config = EmbeddingConfiguration()
        embedding_service = HuggingFaceEmbedding(embedding_config)

        chroma_config = ChromaDBConfig()
        vector_store = VectorStore(chroma_config, embedding_service)

        # 1000ê°œ í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ìƒì„±
        documents = [
            f"í…ŒìŠ¤íŠ¸ ë¬¸ì„œ {i}: PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ íŠ¸ëœì­ì…˜"
            for i in range(1000)
        ]

        vector_store.add_documents(documents)

        return vector_store

    def test_single_query_response_time(self, setup_vector_store):
        """ë‹¨ì¼ ì¿¼ë¦¬ ì‘ë‹µì‹œê°„ ì¸¡ì • (100íšŒ ë°˜ë³µ)"""
        vector_store = setup_vector_store
        query = "ë°ì´í„°ë² ì´ìŠ¤ íŠ¸ëœì­ì…˜"

        response_times = []

        for _ in range(100):
            start = time.time()
            results = vector_store.query(query, top_k=5)
            elapsed = time.time() - start

            response_times.append(elapsed)
            assert len(results["documents"]) == 5

        # í†µê³„ ê³„ì‚°
        mean_time = np.mean(response_times)
        p95_time = np.percentile(response_times, 95)
        p99_time = np.percentile(response_times, 99)

        print(f"\n=== Single Query Performance ===")
        print(f"Mean: {mean_time:.3f}s")
        print(f"P95: {p95_time:.3f}s")
        print(f"P99: {p99_time:.3f}s")

        # SLA ê²€ì¦
        assert p95_time <= 0.5, f"P95 latency {p95_time:.3f}s exceeds SLA of 0.5s"
        assert mean_time <= 0.3, f"Mean latency {mean_time:.3f}s exceeds target of 0.3s"

    def test_concurrent_queries(self, setup_vector_store):
        """ë™ì‹œ 10ê°œ ì¿¼ë¦¬ ì‘ë‹µì‹œê°„ ì¸¡ì •"""
        import concurrent.futures

        vector_store = setup_vector_store
        queries = [f"ì¿¼ë¦¬ {i}" for i in range(10)]

        start = time.time()

        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
            futures = [
                executor.submit(vector_store.query, query, 5)
                for query in queries
            ]
            results = [f.result() for f in futures]

        elapsed = time.time() - start
        avg_time = elapsed / 10

        print(f"\n=== Concurrent Queries Performance ===")
        print(f"Total time: {elapsed:.3f}s")
        print(f"Average per query: {avg_time:.3f}s")

        # SLA ê²€ì¦
        assert avg_time <= 0.7, f"Concurrent query avg {avg_time:.3f}s exceeds target of 0.7s"

    @pytest.mark.parametrize("doc_count", [1000, 5000, 10000])
    def test_scalability(self, doc_count):
        """ë¬¸ì„œ ìˆ˜ë³„ ê²€ìƒ‰ ì„±ëŠ¥"""
        # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        embedding_config = EmbeddingConfiguration()
        embedding_service = HuggingFaceEmbedding(embedding_config)

        chroma_config = ChromaDBConfig()
        vector_store = VectorStore(chroma_config, embedding_service)

        # ë¬¸ì„œ ì¸ë±ì‹±
        documents = [f"ë¬¸ì„œ {i}" for i in range(doc_count)]
        vector_store.add_documents(documents)

        # ì¿¼ë¦¬ ì„±ëŠ¥ ì¸¡ì •
        response_times = []
        for _ in range(20):
            start = time.time()
            vector_store.query("í…ŒìŠ¤íŠ¸", top_k=5)
            elapsed = time.time() - start
            response_times.append(elapsed)

        p95_time = np.percentile(response_times, 95)

        print(f"\n=== Scalability Test (docs={doc_count}) ===")
        print(f"P95: {p95_time:.3f}s")

        # 10000ê°œ ë¬¸ì„œì—ì„œë„ â‰¤0.5ì´ˆ ìœ ì§€
        assert p95_time <= 0.5
```

#### ìˆ˜ë½ ê¸°ì¤€
- âœ… ë‹¨ì¼ ì¿¼ë¦¬ P95 â‰¤0.5ì´ˆ
- âœ… ë‹¨ì¼ ì¿¼ë¦¬ í‰ê·  â‰¤0.3ì´ˆ
- âœ… ë™ì‹œ 10 ì¿¼ë¦¬ í‰ê·  â‰¤0.7ì´ˆ
- âœ… 10000 ë¬¸ì„œì—ì„œë„ P95 â‰¤0.5ì´ˆ
- âœ… ëª¨ë“  ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í†µê³¼

#### ì‚°ì¶œë¬¼
- `tests/integration/test_vector_search.py` (ìƒˆ íŒŒì¼)

---

### T047: Top-5 ì •í™•ë„ ë²¤ì¹˜ë§ˆí¬

**ìš°ì„ ìˆœìœ„**: P0 (Critical)
**ì˜ˆìƒ ì‹œê°„**: 6ì‹œê°„
**ë‹´ë‹¹**: QA Engineer
**ì„ í–‰ ì‘ì—…**: T043

#### ëª©í‘œ
í•œêµ­ì–´ ê²€ìƒ‰ ì •í™•ë„ â‰¥90% (Top-5) ê²€ì¦

#### ì‘ì—… ë‚´ìš©

##### 1. í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì¤€ë¹„
**íŒŒì¼**: `tests/benchmarks/data/queries.json`

```json
[
  {
    "query_id": 1,
    "query": "PostgreSQLì—ì„œ íŠ¸ëœì­ì…˜ ê²©ë¦¬ ìˆ˜ì¤€ì´ë€?",
    "language": "korean",
    "category": "factual",
    "answer_ids": ["doc_123", "doc_456"]
  },
  {
    "query_id": 2,
    "query": "ë°ì´í„°ë² ì´ìŠ¤ ì¸ë±ìŠ¤ì˜ ì¢…ë¥˜",
    "language": "korean",
    "category": "factual",
    "answer_ids": ["doc_789"]
  }
  // ... 100ê°œ ì¿¼ë¦¬
]
```

##### 2. ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ ì‘ì„±
**íŒŒì¼**: `tests/benchmarks/test_embedding_accuracy.py`

```python
import pytest
import json
from pathlib import Path
from typing import List, Dict
from src.services.embeddings import HuggingFaceEmbedding
from src.services.vector_store import VectorStore
from src.models.embedding import EmbeddingConfiguration
from src.config.chroma import ChromaDBConfig

class TestEmbeddingAccuracy:
    """ì„ë² ë”© ê²€ìƒ‰ ì •í™•ë„ ë²¤ì¹˜ë§ˆí¬"""

    @pytest.fixture(scope="class")
    def setup_benchmark(self):
        """ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° ì¤€ë¹„"""
        # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        embedding_config = EmbeddingConfiguration()
        embedding_service = HuggingFaceEmbedding(embedding_config)

        chroma_config = ChromaDBConfig()
        vector_store = VectorStore(chroma_config, embedding_service)

        # ë¬¸ì„œ ë¡œë”©
        doc_path = Path(__file__).parent / "data" / "documents.json"
        with open(doc_path, 'r', encoding='utf-8') as f:
            documents = json.load(f)

        # ì¸ë±ì‹±
        texts = [doc["text"] for doc in documents]
        metadatas = [{"doc_id": doc["id"]} for doc in documents]
        ids = [doc["id"] for doc in documents]

        vector_store.add_documents(
            documents=texts,
            metadatas=metadatas,
            ids=ids
        )

        # ì¿¼ë¦¬ ë¡œë”©
        query_path = Path(__file__).parent / "data" / "queries.json"
        with open(query_path, 'r', encoding='utf-8') as f:
            queries = json.load(f)

        return vector_store, queries

    def test_overall_top5_accuracy(self, setup_benchmark):
        """ì „ì²´ Top-5 ì •í™•ë„ í…ŒìŠ¤íŠ¸"""
        vector_store, queries = setup_benchmark

        hits = 0
        total = len(queries)

        for query_data in queries:
            query = query_data["query"]
            answer_ids = set(query_data["answer_ids"])

            # Top-5 ê²€ìƒ‰
            results = vector_store.query(query, top_k=5)
            result_ids = set(
                [meta["doc_id"] for meta in results["metadatas"]]
            )

            # Hit@5 ê³„ì‚°
            if answer_ids & result_ids:  # êµì§‘í•©ì´ ìˆìœ¼ë©´ hit
                hits += 1

        accuracy = hits / total

        print(f"\n=== Overall Top-5 Accuracy ===")
        print(f"Hits: {hits}/{total}")
        print(f"Accuracy: {accuracy:.2%}")

        # SLA ê²€ì¦
        assert accuracy >= 0.90, f"Accuracy {accuracy:.2%} below target of 90%"

    def test_korean_query_accuracy(self, setup_benchmark):
        """í•œêµ­ì–´ ì¿¼ë¦¬ ì •í™•ë„"""
        vector_store, queries = setup_benchmark

        korean_queries = [q for q in queries if q["language"] == "korean"]

        hits = 0
        for query_data in korean_queries:
            query = query_data["query"]
            answer_ids = set(query_data["answer_ids"])

            results = vector_store.query(query, top_k=5)
            result_ids = set(
                [meta["doc_id"] for meta in results["metadatas"]]
            )

            if answer_ids & result_ids:
                hits += 1

        accuracy = hits / len(korean_queries)

        print(f"\n=== Korean Query Accuracy ===")
        print(f"Hits: {hits}/{len(korean_queries)}")
        print(f"Accuracy: {accuracy:.2%}")

        assert accuracy >= 0.90

    def test_category_accuracy(self, setup_benchmark):
        """ì¹´í…Œê³ ë¦¬ë³„ ì •í™•ë„"""
        vector_store, queries = setup_benchmark

        categories = set(q["category"] for q in queries)

        for category in categories:
            cat_queries = [q for q in queries if q["category"] == category]

            hits = 0
            for query_data in cat_queries:
                query = query_data["query"]
                answer_ids = set(query_data["answer_ids"])

                results = vector_store.query(query, top_k=5)
                result_ids = set(
                    [meta["doc_id"] for meta in results["metadatas"]]
                )

                if answer_ids & result_ids:
                    hits += 1

            accuracy = hits / len(cat_queries)

            print(f"\n=== {category.title()} Accuracy ===")
            print(f"Accuracy: {accuracy:.2%}")

    def test_mrr(self, setup_benchmark):
        """Mean Reciprocal Rank ê³„ì‚°"""
        vector_store, queries = setup_benchmark

        reciprocal_ranks = []

        for query_data in queries:
            query = query_data["query"]
            answer_ids = set(query_data["answer_ids"])

            results = vector_store.query(query, top_k=5)
            result_ids = [meta["doc_id"] for meta in results["metadatas"]]

            # ì²« ë²ˆì§¸ ì •ë‹µì˜ ìˆœìœ„ ì°¾ê¸°
            rank = None
            for i, doc_id in enumerate(result_ids, 1):
                if doc_id in answer_ids:
                    rank = i
                    break

            if rank:
                reciprocal_ranks.append(1 / rank)
            else:
                reciprocal_ranks.append(0)

        mrr = sum(reciprocal_ranks) / len(reciprocal_ranks)

        print(f"\n=== Mean Reciprocal Rank ===")
        print(f"MRR: {mrr:.3f}")

        assert mrr >= 0.75
```

##### 3. ë¦¬í¬íŠ¸ ìƒì„±
**íŒŒì¼**: `tests/benchmarks/generate_accuracy_report.py`

```python
def generate_html_report(results: Dict):
    """HTML ë¦¬í¬íŠ¸ ìƒì„±"""
    html = f"""
    <html>
    <head><title>Embedding Accuracy Report</title></head>
    <body>
        <h1>Embedding Accuracy Benchmark</h1>
        <h2>Overall Results</h2>
        <p>Top-5 Accuracy: {results['overall_accuracy']:.2%}</p>
        <p>MRR: {results['mrr']:.3f}</p>

        <h2>Language Breakdown</h2>
        <ul>
            <li>Korean: {results['korean_accuracy']:.2%}</li>
            <li>English: {results['english_accuracy']:.2%}</li>
            <li>Mixed: {results['mixed_accuracy']:.2%}</li>
        </ul>

        <h2>Category Breakdown</h2>
        <ul>
            {''.join([f'<li>{cat}: {acc:.2%}</li>' for cat, acc in results['category_accuracy'].items()])}
        </ul>

        <h2>Failed Queries</h2>
        <ul>
            {''.join([f'<li>{q}</li>' for q in results['failed_queries']])}
        </ul>
    </body>
    </html>
    """

    with open("benchmark_report.html", "w") as f:
        f.write(html)
```

#### ìˆ˜ë½ ê¸°ì¤€
- âœ… 100ê°œ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì¤€ë¹„ (í•œêµ­ì–´ 50, ì˜ì–´ 30, í˜¼í•© 20)
- âœ… ì „ì²´ Top-5 Accuracy â‰¥90%
- âœ… í•œêµ­ì–´ ì¿¼ë¦¬ ì •í™•ë„ â‰¥90%
- âœ… MRR â‰¥0.75
- âœ… ì¹´í…Œê³ ë¦¬ë³„ ì •í™•ë„ ë¦¬í¬íŠ¸ ìƒì„±
- âœ… ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ë¶„ì„ ë¦¬í¬íŠ¸

#### ì‚°ì¶œë¬¼
- `tests/benchmarks/test_embedding_accuracy.py` (ìƒˆ íŒŒì¼)
- `tests/benchmarks/data/queries.json` (ìƒˆ íŒŒì¼)
- `tests/benchmarks/data/documents.json` (ìƒˆ íŒŒì¼)
- `benchmark_report.html` (ê²°ê³¼ ë¦¬í¬íŠ¸)

---

### T048: ë‹¤êµ­ì–´ ì§€ì› í…ŒìŠ¤íŠ¸

**ìš°ì„ ìˆœìœ„**: P2 (Medium)
**ì˜ˆìƒ ì‹œê°„**: 3ì‹œê°„
**ë‹´ë‹¹**: QA Engineer
**ì„ í–‰ ì‘ì—…**: T045

#### ëª©í‘œ
ë‹¤êµ­ì–´ ë° íŠ¹ìˆ˜ ë¬¸ì ì²˜ë¦¬ ê²€ì¦

#### ì‘ì—… ë‚´ìš©

##### 1. í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì¶”ê°€
**íŒŒì¼**: `tests/unit/test_embeddings.py` (ê¸°ì¡´ íŒŒì¼ì— ì¶”ê°€)

```python
class TestMultilingualSupport:
    """ë‹¤êµ­ì–´ ì§€ì› í…ŒìŠ¤íŠ¸"""

    @pytest.fixture
    def embedding_service(self):
        config = EmbeddingConfiguration()
        return HuggingFaceEmbedding(config)

    @pytest.mark.parametrize("text,language", [
        ("ë°ì´í„°ë² ì´ìŠ¤ ì¸ë±ìŠ¤", "korean"),
        ("database index", "english"),
        ("PostgreSQLì˜ B-tree ì¸ë±ìŠ¤", "mixed"),
        ("æ—¥æœ¬èªã®ãƒ†ã‚­ã‚¹ãƒˆ", "japanese"),
        ("ä¸­æ–‡æ–‡æœ¬", "chinese"),
    ])
    def test_multilingual_embedding(self, embedding_service, text, language):
        """ë‹¤êµ­ì–´ í…ìŠ¤íŠ¸ ì„ë² ë”©"""
        embedding = embedding_service.embed_text(text)

        assert len(embedding) == 384
        print(f"{language}: {text} â†’ embedding generated")

    def test_special_characters(self, embedding_service):
        """íŠ¹ìˆ˜ ë¬¸ì ì²˜ë¦¬"""
        texts = [
            "SQLì˜ WHERE ì¡°ê±´ì ˆ (condition)",
            "Python f-string {variable}",
            "ì •ê·œí‘œí˜„ì‹ [a-zA-Z]+",
            "ì´ëª¨ì§€ í¬í•¨ ğŸ˜€ í…ìŠ¤íŠ¸",
        ]

        for text in texts:
            embedding = embedding_service.embed_text(text)
            assert len(embedding) == 384

    def test_unicode_normalization(self, embedding_service):
        """ìœ ë‹ˆì½”ë“œ ì •ê·œí™”"""
        # NFD vs NFC í˜•ì‹
        text_nfd = "í•œê¸€"  # NFD
        text_nfc = "í•œê¸€"  # NFC

        embedding_nfd = embedding_service.embed_text(text_nfd)
        embedding_nfc = embedding_service.embed_text(text_nfc)

        # ì„ë² ë”©ì´ ìœ ì‚¬í•´ì•¼ í•¨ (ì™„ì „íˆ ë™ì¼í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ)
        import numpy as np
        similarity = np.dot(embedding_nfd, embedding_nfc)
        assert similarity > 0.99  # ë§¤ìš° ë†’ì€ ìœ ì‚¬ë„

    def test_encoding_edge_cases(self, embedding_service):
        """ì¸ì½”ë”© ì—£ì§€ ì¼€ì´ìŠ¤"""
        texts = [
            "\n\n\ní…ìŠ¤íŠ¸\n\n",  # ê°œí–‰ ë¬¸ì
            "\t\tí…ìŠ¤íŠ¸\t\t",  # íƒ­ ë¬¸ì
            "   í…ìŠ¤íŠ¸   ",  # ê³µë°±
            "í…ìŠ¤íŠ¸\r\nìœˆë„ìš°",  # CRLF
        ]

        for text in texts:
            embedding = embedding_service.embed_text(text)
            assert len(embedding) == 384
```

#### ìˆ˜ë½ ê¸°ì¤€
- âœ… í•œêµ­ì–´, ì˜ì–´, ì¼ë³¸ì–´, ì¤‘êµ­ì–´ í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì„±ê³µ
- âœ… íŠ¹ìˆ˜ ë¬¸ì í¬í•¨ í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì„±ê³µ
- âœ… ìœ ë‹ˆì½”ë“œ ì •ê·œí™” ì²˜ë¦¬ ì„±ê³µ
- âœ… ì¸ì½”ë”© ì—£ì§€ ì¼€ì´ìŠ¤ ì²˜ë¦¬ ì„±ê³µ
- âœ… ì¸ì½”ë”© ì˜¤ë¥˜ 0ê±´

#### ì‚°ì¶œë¬¼
- `tests/unit/test_embeddings.py` (ì—…ë°ì´íŠ¸)

---

### T049: ë¬¸ì„œí™”

**ìš°ì„ ìˆœìœ„**: P2 (Medium)
**ì˜ˆìƒ ì‹œê°„**: 4ì‹œê°„
**ë‹´ë‹¹**: Technical Writer
**ì„ í–‰ ì‘ì—…**: T041-T048

#### ëª©í‘œ
ì„ë² ë”© ëª¨ë¸ ì‚¬ì–‘ ë° API ì‚¬ìš© ê°€ì´ë“œ ë¬¸ì„œ ì‘ì„±

#### ì‘ì—… ë‚´ìš©

##### 1. ëª¨ë¸ ì‚¬ì–‘ ë¬¸ì„œ
**íŒŒì¼**: `docs/embedding-model.md`

```markdown
# Embedding Model Specification

## Model Information

**Name**: paraphrase-multilingual-MiniLM-L12-v2
**Source**: Hugging Face sentence-transformers
**Architecture**: MiniLM (12-layer Transformer)

## Specifications

- **Embedding Dimension**: 384
- **Max Sequence Length**: 512 tokens
- **Normalization**: L2 normalized
- **Similarity Metric**: Cosine similarity

## Supported Languages

- Korean (í•œêµ­ì–´)
- English
- Japanese (æ—¥æœ¬èª)
- Chinese (ä¸­æ–‡)
- 50+ languages total

## Performance Benchmarks

### Accuracy
- Top-5 Accuracy: 92%
- Mean Reciprocal Rank: 0.78

### Latency
- Single query P95: 0.32s
- Concurrent (10 queries) avg: 0.45s

### Memory
- Model size: ~470MB
- Runtime memory: <1GB
```

##### 2. API ì‚¬ìš© ê°€ì´ë“œ
**íŒŒì¼**: `docs/embedding-api-guide.md`

```markdown
# Embedding API Usage Guide

## Quick Start

### Installation
```bash
pip install sentence-transformers>=2.2.0 chromadb>=0.4.0
```

### Basic Usage
```python
from src.services.embeddings import HuggingFaceEmbedding
from src.models.embedding import EmbeddingConfiguration

# Initialize
config = EmbeddingConfiguration()
embedding_service = HuggingFaceEmbedding(config)

# Single text
vector = embedding_service.embed_text("í•œêµ­ì–´ í…ìŠ¤íŠ¸")

# Batch texts
vectors = embedding_service.embed_texts(["text1", "text2"])
```

## API Reference

### HuggingFaceEmbedding

#### `__init__(config: EmbeddingConfiguration)`
...

#### `embed_text(text: str) -> List[float]`
...

## Best Practices

1. **Batch Processing**: Always use `embed_texts()` for multiple documents
2. **Error Handling**: Validate input text length
3. **Performance**: Adjust batch size based on available memory
```

##### 3. íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ
**íŒŒì¼**: `docs/embedding-troubleshooting.md`

```markdown
# Embedding Troubleshooting Guide

## Common Issues

### Issue 1: Slow Embedding Generation

**Symptoms**: Embedding takes >2s for 100 documents

**Solutions**:
- Reduce batch size
- Check CPU usage
- Disable progress bar

### Issue 2: Out of Memory

**Symptoms**: `MemoryError` during batch processing

**Solutions**:
- Reduce batch size to 50 or 25
- Process in smaller chunks
```

##### 4. FAQ
**íŒŒì¼**: `docs/embedding-faq.md`

```markdown
# Embedding FAQ

## Q1: Why 384 dimensions?

The paraphrase-multilingual-MiniLM-L12-v2 model outputs 384-dimensional vectors...

## Q2: Can I use GPU?

Yes, set `device=DeviceType.CUDA` in configuration...

## Q3: How to improve accuracy?

- Use larger batch sizes
- Ensure text is preprocessed
- Consider hybrid search (BM25 + vector)
```

#### ìˆ˜ë½ ê¸°ì¤€
- âœ… ëª¨ë¸ ì‚¬ì–‘ ë¬¸ì„œ ì™„ì„±
- âœ… API ì‚¬ìš© ê°€ì´ë“œ ì‘ì„± (ì½”ë“œ ì˜ˆì‹œ í¬í•¨)
- âœ… íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ ì‘ì„±
- âœ… FAQ ì‘ì„± (10ê°œ ì´ìƒ ì§ˆë¬¸)
- âœ… ëª¨ë“  ì½”ë“œ ì˜ˆì‹œ ì •í™•ì„± ê²€ì¦

#### ì‚°ì¶œë¬¼
- `docs/embedding-model.md` (ìƒˆ íŒŒì¼)
- `docs/embedding-api-guide.md` (ìƒˆ íŒŒì¼)
- `docs/embedding-troubleshooting.md` (ìƒˆ íŒŒì¼)
- `docs/embedding-faq.md` (ìƒˆ íŒŒì¼)

---

## ì¢…ì†ì„± ë‹¤ì´ì–´ê·¸ë¨

```
T041 (ëª¨ë¸ ì„¤ì • ê²€ì¦)
  â†“
T042 (ì„ë² ë”© ì„œë¹„ìŠ¤ êµ¬í˜„) â­
  â†“
T043 (ChromaDB í†µí•©)
  â†“
T044 (ë¬¸ì„œ ì¸ë±ì‹± ìœ í‹¸ë¦¬í‹°)
  â†“
T045 (í•œêµ­ì–´ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸) â† T042
  â†“
T046 (ë²¡í„° ê²€ìƒ‰ ì§€ì—°ì‹œê°„ í…ŒìŠ¤íŠ¸) â† T043
  â†“
T047 (Top-5 ì •í™•ë„ ë²¤ì¹˜ë§ˆí¬) â† T043
  â†“
T048 (ë‹¤êµ­ì–´ ì§€ì› í…ŒìŠ¤íŠ¸) â† T045
  â†“
T049 (ë¬¸ì„œí™”) â† T041-T048
```

---

## íƒ€ì„ë¼ì¸ (3ì£¼)

### Week 1: ì„œë¹„ìŠ¤ êµ¬í˜„
- **Day 1-2**: T041 + T042
- **Day 3-4**: T043
- **Day 5**: T044

**Milestone**: 1000ê°œ ë¬¸ì„œ ì¸ë±ì‹± ì„±ê³µ

### Week 2: í…ŒìŠ¤íŠ¸ ë° ê²€ì¦
- **Day 1-2**: T045
- **Day 3**: T046
- **Day 4-5**: T047
- **Day 6**: T048

**Milestone**: ëª¨ë“  ìˆ˜ë½ ê¸°ì¤€ í†µê³¼

### Week 3: ë¬¸ì„œí™” ë° ë°°í¬
- **Day 1-2**: T049
- **Day 3-4**: ì„±ëŠ¥ ìµœì í™” (í•„ìš” ì‹œ)
- **Day 5**: ìµœì¢… ê²€ì¦ ë° ë°°í¬ ì¤€ë¹„

**Milestone**: Phase 4 ì™„ë£Œ

---

## ë¦¬ìŠ¤í¬ ë° ì™„í™” ì „ëµ

### ë¦¬ìŠ¤í¬ 1: í•œêµ­ì–´ ì„ë² ë”© í’ˆì§ˆ ë¯¸ë‹¬
- **í™•ë¥ **: ë‚®ìŒ
- **ì˜í–¥**: ë†’ìŒ
- **ì™„í™”**: ì‚¬ì „ í…ŒìŠ¤íŠ¸, í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í™œìš©

### ë¦¬ìŠ¤í¬ 2: ê²€ìƒ‰ ì§€ì—°ì‹œê°„ SLA ë¯¸ë‹¬
- **í™•ë¥ **: ì¤‘ê°„
- **ì˜í–¥**: ì¤‘ê°„
- **ì™„í™”**: ë°°ì¹˜ í¬ê¸° ìµœì í™”, ìºì‹± ì „ëµ

### ë¦¬ìŠ¤í¬ 3: ë©”ëª¨ë¦¬ ë¶€ì¡±
- **í™•ë¥ **: ë‚®ìŒ
- **ì˜í–¥**: ì¤‘ê°„
- **ì™„í™”**: ë™ì  ë°°ì¹˜ í¬ê¸° ì¡°ì •, ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬

---

**Version**: 1.0.0
**Last Updated**: 2025-01-17
**Status**: Ready for Implementation
**Total Estimated Hours**: 32 hours
