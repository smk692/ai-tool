# Quickstart Guide: Hugging Face ì„ë² ë”© í†µí•©

**Feature**: 002-embedding-validation
**Version**: 1.0.0
**Last Updated**: 2025-01-17

---

## ê°œìš”

ì´ ê°€ì´ë“œëŠ” Hugging Face sentence-transformers ê¸°ë°˜ ì„ë² ë”© ì„œë¹„ìŠ¤ë¥¼ ë¹ ë¥´ê²Œ ì‹œì‘í•˜ëŠ” ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.

**ì£¼ìš” ê¸°ëŠ¥**:
- ğŸŒ ë‹¤êµ­ì–´ ì§€ì› (í•œêµ­ì–´, ì˜ì–´ ë“± 50+ ì–¸ì–´)
- âš¡ ë¹ ë¥¸ ì„ë² ë”© ìƒì„± (ë°°ì¹˜ 100ê°œ â‰¤2ì´ˆ)
- ğŸ¯ ë†’ì€ ê²€ìƒ‰ ì •í™•ë„ (Top-5 â‰¥90%)
- ğŸ’¾ ChromaDB ë²¡í„° ìŠ¤í† ì–´ í†µí•©

---

## 1. ì„¤ì¹˜ ë° ì„¤ì •

### 1.1 ì˜ì¡´ì„± ì„¤ì¹˜

```bash
# í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ì´ë™
cd ai-tool

# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install sentence-transformers>=2.2.0 chromadb>=0.4.0
```

### 1.2 í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

`.env` íŒŒì¼ì— ë‹¤ìŒ ì„¤ì •ì„ ì¶”ê°€í•˜ì„¸ìš”:

```bash
# Embedding Model Configuration
EMBEDDING_MODEL_NAME=paraphrase-multilingual-MiniLM-L12-v2
EMBEDDING_DEVICE=cpu  # cpu | cuda | mps
EMBEDDING_BATCH_SIZE=100
EMBEDDING_MAX_SEQUENCE_LENGTH=512

# Vector Store Configuration
CHROMA_PERSIST_DIRECTORY=./data/chroma
CHROMA_COLLECTION_NAME=documents
CHROMA_DISTANCE_FUNCTION=cosine
```

### 1.3 ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ì„ íƒì‚¬í•­)

ì²« ì‹¤í–‰ ì‹œ ëª¨ë¸ì´ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œë˜ì§€ë§Œ, ì‚¬ì „ ë‹¤ìš´ë¡œë“œë„ ê°€ëŠ¥í•©ë‹ˆë‹¤:

```bash
python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')"
```

**ëª¨ë¸ í¬ê¸°**: ~470MB
**ë‹¤ìš´ë¡œë“œ ìœ„ì¹˜**: `~/.cache/torch/sentence_transformers/`

---

## 2. ì„ë² ë”© ì„œë¹„ìŠ¤ ì‚¬ìš©

### 2.1 ê¸°ë³¸ ì‚¬ìš©ë²•

```python
from src.services.embeddings import HuggingFaceEmbedding
from src.models.embedding import EmbeddingConfiguration

# 1. ì„¤ì • ì´ˆê¸°í™”
config = EmbeddingConfiguration()

# 2. ì„ë² ë”© ì„œë¹„ìŠ¤ ìƒì„±
embedding_service = HuggingFaceEmbedding(config)

# 3. ë‹¨ì¼ í…ìŠ¤íŠ¸ ì„ë² ë”©
vector = embedding_service.embed_text("PostgreSQL íŠ¸ëœì­ì…˜ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?")
print(f"ì„ë² ë”© ì°¨ì›: {len(vector)}")  # 384
print(f"ë²¡í„° ìƒ˜í”Œ: {vector[:5]}")

# 4. ë°°ì¹˜ ì„ë² ë”©
texts = [
    "ë°ì´í„°ë² ì´ìŠ¤ ì¸ë±ìŠ¤ ì¢…ë¥˜",
    "SQL ì¿¼ë¦¬ ìµœì í™” ë°©ë²•",
    "NoSQLê³¼ ê´€ê³„í˜• ë°ì´í„°ë² ì´ìŠ¤ ì°¨ì´"
]
vectors = embedding_service.embed_texts(texts)
print(f"ìƒì„±ëœ ì„ë² ë”© ìˆ˜: {len(vectors)}")  # 3
```

### 2.2 GPU ì‚¬ìš© (ì˜µì…˜)

```python
from src.models.embedding import EmbeddingConfiguration, DeviceType

# CUDA GPU ì‚¬ìš©
config_gpu = EmbeddingConfiguration(
    device=DeviceType.CUDA,
    batch_size=200  # GPUì—ì„œ ë” í° ë°°ì¹˜ í¬ê¸°
)
embedding_service = HuggingFaceEmbedding(config_gpu)

# Apple Silicon MPS ì‚¬ìš©
config_mps = EmbeddingConfiguration(
    device=DeviceType.MPS,
    batch_size=150
)
embedding_service = HuggingFaceEmbedding(config_mps)
```

---

## 3. ë¬¸ì„œ ì¸ë±ì‹±

### 3.1 í”„ë¡œê·¸ë˜ë° ë°©ì‹

```python
from src.services.embeddings import HuggingFaceEmbedding
from src.services.vector_store import VectorStore
from src.models.embedding import EmbeddingConfiguration
from src.config.chroma import ChromaDBConfig

# 1. ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
embedding_config = EmbeddingConfiguration()
embedding_service = HuggingFaceEmbedding(embedding_config)

chroma_config = ChromaDBConfig()
vector_store = VectorStore(chroma_config, embedding_service)

# 2. ë¬¸ì„œ ì¤€ë¹„
documents = [
    "PostgreSQLì€ ê°ì²´-ê´€ê³„í˜• ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.",
    "ì¸ë±ìŠ¤ëŠ” ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.",
    "íŠ¸ëœì­ì…˜ì€ ACID ì†ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤."
]

metadatas = [
    {"source": "postgresql_intro.md", "category": "database"},
    {"source": "index_guide.md", "category": "performance"},
    {"source": "transaction_guide.md", "category": "database"}
]

# 3. ë¬¸ì„œ ì¶”ê°€ (ì„ë² ë”© ìë™ ìƒì„±)
result = vector_store.add_documents(
    documents=documents,
    metadatas=metadatas
)

print(f"ì¶”ê°€ëœ ë¬¸ì„œ ìˆ˜: {result['count']}")
print(f"ë¬¸ì„œ ID: {result['ids']}")
```

### 3.2 ìŠ¤í¬ë¦½íŠ¸ ë°©ì‹ (ëŒ€ëŸ‰ ì²˜ë¦¬)

```bash
# JSON íŒŒì¼ì—ì„œ ë¬¸ì„œ ì¸ë±ì‹±
python scripts/index_documents.py \
    --source data/documents/ \
    --format json \
    --batch-size 100

# CSV íŒŒì¼ì—ì„œ ë¬¸ì„œ ì¸ë±ì‹±
python scripts/index_documents.py \
    --source data/faq.csv \
    --format csv \
    --text-column question \
    --batch-size 50
```

**ì§€ì› í˜•ì‹**: JSON, CSV, TXT, Markdown

---

## 4. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸

### 4.1 ê¸°ë³¸ ê²€ìƒ‰

```python
from src.services.vector_store import VectorStore

# ì¿¼ë¦¬ ì‹¤í–‰
query_text = "ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ ìµœì í™”"
results = vector_store.query(query_text, top_k=5)

# ê²°ê³¼ ì¶œë ¥
for i, (doc, metadata, distance) in enumerate(
    zip(results['documents'], results['metadatas'], results['distances'])
):
    similarity = 1 - distance  # Cosine similarity
    print(f"\n[{i+1}] ìœ ì‚¬ë„: {similarity:.3f}")
    print(f"ë¬¸ì„œ: {doc}")
    print(f"ì¶œì²˜: {metadata.get('source', 'N/A')}")
```

### 4.2 í•„í„°ë§ ê²€ìƒ‰

```python
# ë©”íƒ€ë°ì´í„° í•„í„° ì ìš©
results = vector_store.query(
    query_text="SQL ì¿¼ë¦¬",
    top_k=3,
    filter={"category": "database"}  # categoryê°€ 'database'ì¸ ë¬¸ì„œë§Œ
)
```

---

## 5. ì„±ëŠ¥ ê²€ì¦

### 5.1 ì„ë² ë”© ìƒì„± ì†ë„

```python
import time
from src.services.embeddings import HuggingFaceEmbedding
from src.models.embedding import EmbeddingConfiguration

config = EmbeddingConfiguration(batch_size=100)
embedding_service = HuggingFaceEmbedding(config)

# 100ê°œ ë¬¸ì„œ ì„ë² ë”© ìƒì„± ì‹œê°„ ì¸¡ì •
texts = ["í…ŒìŠ¤íŠ¸ ë¬¸ì„œ"] * 100

start = time.time()
vectors = embedding_service.embed_texts(texts)
elapsed = time.time() - start

print(f"100ê°œ ë¬¸ì„œ ì„ë² ë”© ìƒì„±: {elapsed:.2f}ì´ˆ")
print(f"ë¬¸ì„œë‹¹ í‰ê· : {elapsed/100*1000:.1f}ms")
# ì˜ˆìƒ ê²°ê³¼ (CPU): ~2ì´ˆ, ë¬¸ì„œë‹¹ ~20ms
```

### 5.2 ê²€ìƒ‰ ì •í™•ë„

```bash
# ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest tests/benchmarks/test_embedding_accuracy.py -v

# ì˜ˆìƒ ê²°ê³¼:
# âœ… Top-1 accuracy: ~75%
# âœ… Top-5 accuracy: ~92%
# âœ… Search latency P95: ~0.3ì´ˆ
```

---

## 6. ë¬¸ì œ í•´ê²°

### 6.1 ì¼ë°˜ì ì¸ ë¬¸ì œ

**Q1. ëª¨ë¸ ë‹¤ìš´ë¡œë“œê°€ ëŠë ¤ìš”**

```bash
# í•œêµ­ ë¯¸ëŸ¬ ì„œë²„ ì‚¬ìš© (ì„ íƒì‚¬í•­)
export HF_ENDPOINT=https://hf-mirror.com
python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')"
```

**Q2. CUDA out of memory ì˜¤ë¥˜**

```python
# ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
config = EmbeddingConfiguration(
    device=DeviceType.CUDA,
    batch_size=50  # ê¸°ë³¸ê°’ 100 â†’ 50
)
```

**Q3. Apple Siliconì—ì„œ ëŠë ¤ìš”**

```python
# MPS ë””ë°”ì´ìŠ¤ í™œì„±í™”
config = EmbeddingConfiguration(
    device=DeviceType.MPS,  # CPU ëŒ€ì‹  MPS
    batch_size=100
)
```

**Q4. ê²€ìƒ‰ ê²°ê³¼ê°€ ë¶€ì •í™•í•´ìš”**

```python
# 1. ì„ë² ë”© ì°¨ì› í™•ì¸
print(embedding_service.get_embedding_dimension())  # 384ì—¬ì•¼ í•¨

# 2. ëª¨ë¸ ê²€ì¦
is_valid = embedding_service.validate_model()
print(f"ëª¨ë¸ ìœ íš¨ì„±: {is_valid}")  # Trueì—¬ì•¼ í•¨

# 3. ë²¡í„° ì •ê·œí™” í™•ì¸
import numpy as np
vector = embedding_service.embed_text("í…ŒìŠ¤íŠ¸")
magnitude = np.linalg.norm(vector)
print(f"ë²¡í„° í¬ê¸°: {magnitude:.6f}")  # ~1.0ì´ì–´ì•¼ í•¨ (L2 ì •ê·œí™”)
```

### 6.2 ë””ë²„ê¹… ëª¨ë“œ

```python
import logging

# ë””ë²„ê·¸ ë¡œê·¸ í™œì„±í™”
logging.basicConfig(level=logging.DEBUG)

# ì„ë² ë”© ì„œë¹„ìŠ¤ ì‹¤í–‰
embedding_service = HuggingFaceEmbedding(config)
vector = embedding_service.embed_text("í…ŒìŠ¤íŠ¸")
# ìƒì„¸í•œ ì‹¤í–‰ ë¡œê·¸ ì¶œë ¥
```

---

## 7. ë‹¤ìŒ ë‹¨ê³„

### í•™ìŠµ ìë£Œ
- ğŸ“– [ì™„ì „í•œ ê¸°ëŠ¥ ëª…ì„¸](./spec.md)
- ğŸ—ï¸ [êµ¬í˜„ ê³„íš](./plan.md)
- ğŸ“Š [ë°ì´í„° ëª¨ë¸](./data-model.md)
- âœ… [ì‘ì—… ëª©ë¡](./tasks.md)

### ì‹¤ìŠµ ì˜ˆì œ
```bash
# 1. ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest tests/unit/test_embeddings.py -v

# 2. í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest tests/integration/test_vector_search.py -v

# 3. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
pytest tests/benchmarks/test_embedding_accuracy.py -v --benchmark
```

### ì¶”ê°€ ìµœì í™”
- ğŸš€ GPU/MPS ê°€ì† í™œì„±í™”
- ğŸ“¦ ë¬¸ì„œ ë°°ì¹˜ í¬ê¸° íŠœë‹
- ğŸ” ê²€ìƒ‰ í•„í„° í™œìš©
- ğŸ’¾ ChromaDB ì¸ë±ìŠ¤ ìµœì í™”

---

**Version**: 1.0.0
**Last Updated**: 2025-01-17
**Status**: Ready for Implementation
**Next Step**: Implement `src/services/embeddings.py` (T042)
