# AI Assistant - Claude Code + Hugging Face Embeddings

í•œêµ­ì–´ ì§€ì› AI ì–´ì‹œìŠ¤í„´íŠ¸ ì‹œìŠ¤í…œ (OpenAI â†’ Anthropic Claude Code ë§ˆì´ê·¸ë ˆì´ì…˜)

## ì£¼ìš” ê¸°ëŠ¥

- **Intent Classification**: ì¿¼ë¦¬ ìœ í˜• ìë™ ë¶„ë¥˜ (Text-to-SQL, Knowledge Discovery, General Chat)
- **Text-to-SQL**: í•œêµ­ì–´ ìì—°ì–´ë¥¼ PostgreSQL ì¿¼ë¦¬ë¡œ ë³€í™˜
- **RAG-based Knowledge Discovery**: ChromaDB ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ë¬¸ì„œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ
- **Multilingual Embeddings**: Hugging Face ëª¨ë¸ë¡œ 50+ ì–¸ì–´ ì§€ì› (í•œêµ­ì–´ ìµœì í™”)
- **Multi-turn Conversations**: ì„¸ì…˜ ê¸°ë°˜ ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬
- **Token Usage Tracking**: API ì‚¬ìš©ëŸ‰ ì¶”ì  ë° ì˜ˆì‚° ëª¨ë‹ˆí„°ë§

## ê¸°ìˆ  ìŠ¤íƒ

- **LLM**: Anthropic Claude 3.5 Sonnet (langchain-anthropic)
- **Embeddings**: Hugging Face sentence-transformers (paraphrase-multilingual-MiniLM-L12-v2, 384 dimensions)
- **Vector Store**: ChromaDB (ë¬¸ì„œ ì„ë² ë”© ë° ê²€ìƒ‰)
- **Database**: PostgreSQL (ì½ê¸° ì „ìš© ë¶„ì„), SQLite (ëŒ€í™” ë©”ëª¨ë¦¬)
- **Framework**: LangChain (ì²´ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜)
- **Language**: Python 3.10+

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
ai-tool/
â”œâ”€â”€ config/                  # ì„¤ì • íŒŒì¼
â”‚   â”œâ”€â”€ settings.py         # Pydantic ì„¤ì • ê´€ë¦¬
â”‚   â””â”€â”€ .env.example        # í™˜ê²½ ë³€ìˆ˜ ì˜ˆì œ
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ chains/             # LangChain ì²´ì¸
â”‚   â”‚   â”œâ”€â”€ router.py       # Intent classification
â”‚   â”‚   â”œâ”€â”€ text_to_sql.py  # SQL ìƒì„±
â”‚   â”‚   â”œâ”€â”€ knowledge.py    # RAG ê²€ìƒ‰
â”‚   â”‚   â””â”€â”€ multi_turn.py   # ëŒ€í™” ê´€ë¦¬
â”‚   â”œâ”€â”€ models/             # ë°ì´í„° ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ llm_config.py   # LLM ì„¤ì •
â”‚   â”‚   â””â”€â”€ query_response.py # ìš”ì²­/ì‘ë‹µ
â”‚   â”œâ”€â”€ services/           # í•µì‹¬ ì„œë¹„ìŠ¤
â”‚   â”‚   â”œâ”€â”€ llm_client.py   # Claude API í´ë¼ì´ì–¸íŠ¸
â”‚   â”‚   â”œâ”€â”€ embedding.py    # Hugging Face ì„ë² ë”©
â”‚   â”‚   â””â”€â”€ memory.py       # SQLite ë©”ëª¨ë¦¬
â”‚   â””â”€â”€ utils/              # ìœ í‹¸ë¦¬í‹°
â”‚       â”œâ”€â”€ prompts.py      # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
â”‚       â”œâ”€â”€ logging.py      # ë¡œê¹…
â”‚       â””â”€â”€ errors.py       # ì»¤ìŠ¤í…€ ì˜ˆì™¸
â”œâ”€â”€ scripts/                # ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ test_claude_connection.py
â”‚   â””â”€â”€ init_vector_store.py
â””â”€â”€ tests/                  # í…ŒìŠ¤íŠ¸
    â”œâ”€â”€ fixtures/           # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    â””â”€â”€ unit/              # ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
```

## ì„¤ì¹˜ ë° ì„¤ì •

### 1. ì˜ì¡´ì„± ì„¤ì¹˜

```bash
# Python ê°€ìƒí™˜ê²½ ìƒì„± (ê¶Œì¥)
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt
```

### 2. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```bash
# .env íŒŒì¼ ìƒì„±
cp config/.env.example .env

# .env íŒŒì¼ ìˆ˜ì •
# === LLM Configuration ===
ANTHROPIC_API_KEY=sk-ant-YOUR-ACTUAL-API-KEY

# === Database Configuration ===
POSTGRES_HOST=your-db-host
POSTGRES_PORT=5432
POSTGRES_DB=your_database
POSTGRES_USER=your_user
POSTGRES_PASSWORD=your_password

# === Vector Store Configuration ===
CHROMA_PERSIST_DIRECTORY=./data/chroma
CHROMA_COLLECTION_NAME=documents

# === Embedding Configuration ===
EMBEDDING_MODEL_NAME=paraphrase-multilingual-MiniLM-L12-v2
EMBEDDING_DEVICE=cpu  # ë˜ëŠ” cuda (GPU ì‚¬ìš© ì‹œ)
```

### 3. Claude API ì—°ê²° í…ŒìŠ¤íŠ¸

```bash
python scripts/test_claude_connection.py
```

**ì˜ˆìƒ ì¶œë ¥:**
```
============================================================
Claude API Connection Test
============================================================
âœ… API Key found: sk-ant-***...
âœ… LLM connection test passed

Testing Korean support...
Query: ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ ë‚ ì”¨ëŠ” ì–´ë–¤ê°€ìš”?
Response: [Claudeì˜ í•œêµ­ì–´ ì‘ë‹µ]
Token Usage: Input=20, Output=35, Total=55
```

### 4. ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”

```bash
python scripts/init_vector_store.py
```

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ChromaDBë¥¼ ì´ˆê¸°í™”í•˜ê³  ìƒ˜í”Œ ë¬¸ì„œë¥¼ ì„ë² ë”©í•©ë‹ˆë‹¤.

## ì‚¬ìš© ì˜ˆì œ

### Intent Classification (Router Chain)

```python
from src.chains.router import RouterChain
from src.services.llm_client import LLMClient
from src.models.query_response import QueryRequest, QueryType

llm_client = LLMClient()
router = RouterChain(llm_client)

# Text-to-SQL ì¿¼ë¦¬
query = QueryRequest(
    user_id="user123",
    query_text="ì§€ë‚œë‹¬ ì‹ ê·œ ê°€ì…ì ìˆ˜ëŠ”?"
)
query_type = router.classify(query)
print(query_type)  # QueryType.TEXT_TO_SQL

# Knowledge ì¿¼ë¦¬
query = QueryRequest(
    user_id="user123",
    query_text="íšŒì›ê°€ì… ì ˆì°¨ê°€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"
)
query_type = router.classify(query)
print(query_type)  # QueryType.KNOWLEDGE

# General Assistant ì¿¼ë¦¬
query = QueryRequest(
    user_id="user123",
    query_text="ì•ˆë…•í•˜ì„¸ìš”"
)
query_type = router.classify(query)
print(query_type)  # QueryType.ASSISTANT
```

### Text-to-SQL Chain

```python
from src.chains.text_to_sql import TextToSQLChain
from src.services.llm_client import LLMClient
from src.models.query_response import QueryRequest

llm_client = LLMClient()
text_to_sql = TextToSQLChain(llm_client)

query = QueryRequest(
    user_id="user123",
    query_text="ì§€ë‚œ 7ì¼ê°„ ì¼ë³„ ì‹ ê·œ ê°€ì…ì ìˆ˜ë¥¼ ì¡°íšŒí•´ì£¼ì„¸ìš”"
)

response = text_to_sql.generate_sql(query)
print(response.sql_query)
# SELECT DATE(created_at) as date, COUNT(*) as new_users
# FROM users
# WHERE created_at >= CURRENT_DATE - INTERVAL '7 days'
# GROUP BY DATE(created_at)
# ORDER BY date DESC;

print(f"Confidence: {response.confidence_score}")
print(f"Token Usage: {response.token_usage.total_tokens}")
```

### Knowledge Discovery Chain

```python
from src.chains.knowledge import KnowledgeChain
from src.services.llm_client import LLMClient
from src.services.embedding import HuggingFaceEmbedding
from src.models.query_response import QueryRequest

llm_client = LLMClient()
embedding_service = HuggingFaceEmbedding()
knowledge_chain = KnowledgeChain(llm_client, embedding_service)

query = QueryRequest(
    user_id="user123",
    query_text="íšŒì›ê°€ì…í•  ë•Œ ì´ë©”ì¼ ì¸ì¦ì´ í•„ìš”í•œê°€ìš”?"
)

response = knowledge_chain.search(query, top_k=3)
print(response.answer)
# ë„¤, íšŒì›ê°€ì… ì‹œ ì´ë©”ì¼ ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤.
# ì ˆì°¨ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
# 1. ì´ë©”ì¼ ì£¼ì†Œ ì…ë ¥
# 2. ë¹„ë°€ë²ˆí˜¸ ì„¤ì •
# 3. ì´ë©”ì¼ ì¸ì¦ (ì´ ë‹¨ê³„ì—ì„œ ì¸ì¦ ë©”ì¼ í™•ì¸)
# ...

print(f"Source Documents: {len(response.source_documents)}")
for doc in response.source_documents:
    print(f"- {doc.title} (relevance: {doc.relevance_score:.2f})")
```

### Multi-turn Conversation

```python
from src.chains.multi_turn import MultiTurnChain
from src.services.llm_client import LLMClient
from src.services.memory import SQLiteConversationMemory
from src.models.query_response import QueryRequest

llm_client = LLMClient()
memory = SQLiteConversationMemory()
chat = MultiTurnChain(llm_client, memory)

session_id = "session123"

# ì²« ë²ˆì§¸ ëŒ€í™”
query1 = QueryRequest(
    user_id="user123",
    session_id=session_id,
    query_text="ì•ˆë…•í•˜ì„¸ìš”!"
)
response1 = chat.chat(query1)
print(response1.answer)
# ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?

# ë‘ ë²ˆì§¸ ëŒ€í™” (íˆìŠ¤í† ë¦¬ ì°¸ì¡°)
query2 = QueryRequest(
    user_id="user123",
    session_id=session_id,
    query_text="ì£¼ë¬¸ ë‚´ì—­ì„ í™•ì¸í•˜ê³  ì‹¶ì–´ìš”"
)
response2 = chat.chat(query2)
print(response2.answer)
# ì£¼ë¬¸ ë‚´ì—­ í™•ì¸ì„ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.
# ì–´ë–¤ ê¸°ê°„ì˜ ì£¼ë¬¸ ë‚´ì—­ì„ í™•ì¸í•˜ì‹œê² ì–´ìš”?

# ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ
history = memory.get_conversation_history(session_id, limit=10)
for turn in history:
    print(f"User: {turn['user_message']}")
    print(f"Assistant: {turn['assistant_message']}")
```

## í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
# ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest

# íŠ¹ì • í…ŒìŠ¤íŠ¸ íŒŒì¼ ì‹¤í–‰
pytest tests/unit/test_llm_client.py

# Coverage ë¦¬í¬íŠ¸
pytest --cov=src --cov-report=html
```

## ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

### Embedding Performance
- **Model**: paraphrase-multilingual-MiniLM-L12-v2
- **Top-5 Accuracy**: 92.0% (Korean queries)
- **Search Latency**: ~0.32s (p95, target: â‰¤0.5s)
- **Cross-language Similarity**: Koreanâ†”English 0.971, Koreanâ†”Japanese 0.982

### Claude 3.5 Sonnet Pricing
- **Input**: $3 / 1M tokens
- **Output**: $15 / 1M tokens

### ì˜ˆìƒ í† í° ì‚¬ìš©ëŸ‰
- **Intent Classification**: ~50 tokens/query
- **Text-to-SQL**: ~200-500 tokens/query
- **Knowledge Discovery**: ~500-1000 tokens/query (ë¬¸ì„œ ê¸¸ì´ì— ë”°ë¼)
- **Multi-turn Chat**: ~100-300 tokens/turn (íˆìŠ¤í† ë¦¬ì— ë”°ë¼)

### ì„ë² ë”© ì„±ëŠ¥
- **Model**: paraphrase-multilingual-MiniLM-L12-v2
- **Dimensions**: 384
- **Speed**: ~1000 sentences/sec (CPU), ~10000 sentences/sec (GPU)
- **Cost**: Free (ë¡œì»¬ ì‹¤í–‰)

## ë¬¸ì œ í•´ê²°

### API ì¸ì¦ ì˜¤ë¥˜
```
AuthenticationError: Invalid Anthropic API key
```
**í•´ê²°**: `.env` íŒŒì¼ì˜ `ANTHROPIC_API_KEY`ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”.

### ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì˜¤ë¥˜
```
DatabaseConnectionError: Could not connect to PostgreSQL
```
**í•´ê²°**: PostgreSQL ì—°ê²° ì •ë³´ (í˜¸ìŠ¤íŠ¸, í¬íŠ¸, ì‚¬ìš©ì, ë¹„ë°€ë²ˆí˜¸)ë¥¼ í™•ì¸í•˜ì„¸ìš”.

### ì„ë² ë”© ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨
```
OSError: Can't load tokenizer for 'paraphrase-multilingual-MiniLM-L12-v2'
```
**í•´ê²°**: ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•˜ê³  Hugging Face Hubì—ì„œ ëª¨ë¸ì´ ìë™ ë‹¤ìš´ë¡œë“œë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.

### ChromaDB ì´ˆê¸°í™” ì˜¤ë¥˜
```
ChromaDB collection not found
```
**í•´ê²°**: `python scripts/init_vector_store.py`ë¥¼ ì‹¤í–‰í•˜ì—¬ ë²¡í„° ì €ì¥ì†Œë¥¼ ì´ˆê¸°í™”í•˜ì„¸ìš”.

## ê°œë°œ ë¡œë“œë§µ

### âœ… User Story 1: Claude Code ë§ˆì´ê·¸ë ˆì´ì…˜ (ì™„ë£Œ)
- OpenAI â†’ Anthropic Claude 3.5 Sonnet ì „í™˜
- Intent classification
- Text-to-SQL, Knowledge, Multi-turn chains
- í•œêµ­ì–´ ì§€ì›
- ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (79.93% coverage)

### âœ… User Story 2: Hugging Face ì„ë² ë”© í†µí•© (ì™„ë£Œ)
- HuggingFaceEmbedding ì„œë¹„ìŠ¤ êµ¬í˜„
- ChromaDB í†µí•© ë° ë¬¸ì„œ ì¸ë±ì‹±
- Top-5 ì •í™•ë„: 92.0% (ëª©í‘œ: â‰¥90%)
- ê²€ìƒ‰ ì§€ì—°ì‹œê°„: ~0.32s (ëª©í‘œ: â‰¤0.5s)
- ë‹¤êµ­ì–´ ì§€ì› ê²€ì¦ (Korean, English, Japanese, Chinese)
- í¬ê´„ì ì¸ ë¬¸ì„œí™” (ëª¨ë¸ ì‚¬ì–‘, API ê°€ì´ë“œ, íŠ¸ëŸ¬ë¸”ìŠˆíŒ…, FAQ)

### ğŸ“‹ User Story 3: í–¥í›„ ê³„íš
- í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê°œì„  (BM25 + Vector)
- RAG íŒŒì´í”„ë¼ì¸ ê³ ë„í™”
- í”„ë¡œë•ì…˜ ë°°í¬ ì¤€ë¹„

## ë¼ì´ì„ ìŠ¤

MIT License

## ì—°ë½ì²˜

í”„ë¡œì íŠ¸ ê´€ë ¨ ë¬¸ì˜: [your-email@example.com]
